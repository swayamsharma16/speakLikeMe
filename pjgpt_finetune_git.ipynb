{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T18:51:22.380444Z",
     "iopub.status.busy": "2024-07-14T18:51:22.379634Z",
     "iopub.status.idle": "2024-07-14T18:53:15.667563Z",
     "shell.execute_reply": "2024-07-14T18:53:15.666257Z",
     "shell.execute_reply.started": "2024-07-14T18:51:22.380412Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U transformers \n",
    "%pip install -U datasets \n",
    "%pip install -U accelerate \n",
    "%pip install -U peft \n",
    "%pip install -U trl \n",
    "%pip install -U bitsandbytes \n",
    "%pip install -U wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T18:53:25.722788Z",
     "iopub.status.busy": "2024-07-14T18:53:25.722403Z",
     "iopub.status.idle": "2024-07-14T18:53:48.748919Z",
     "shell.execute_reply": "2024-07-14T18:53:48.747810Z",
     "shell.execute_reply.started": "2024-07-14T18:53:25.722754Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-14 18:53:34.099804: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-14 18:53:34.099921: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-14 18:53:34.263190: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "import os, torch, wandb\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, setup_chat_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T18:53:48.751060Z",
     "iopub.status.busy": "2024-07-14T18:53:48.750420Z",
     "iopub.status.idle": "2024-07-14T18:54:08.188588Z",
     "shell.execute_reply": "2024-07-14T18:54:08.187430Z",
     "shell.execute_reply.started": "2024-07-14T18:53:48.751030Z"
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "hf_token = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "login(token = hf_token)\n",
    "\n",
    "wb_token = user_secrets.get_secret(\"wandb\")\n",
    "\n",
    "wandb.login(key=wb_token)\n",
    "run = wandb.init(\n",
    "    project='Fine-tune Llama 3 8B on trial Dataset', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\"\n",
    ")\n",
    "#Output redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T18:54:12.556091Z",
     "iopub.status.busy": "2024-07-14T18:54:12.555328Z",
     "iopub.status.idle": "2024-07-14T18:54:12.563639Z",
     "shell.execute_reply": "2024-07-14T18:54:12.562126Z",
     "shell.execute_reply.started": "2024-07-14T18:54:12.556058Z"
    }
   },
   "outputs": [],
   "source": [
    "base_model = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "dataset_name = \"/kaggle/input/pjgpt-data\"\n",
    "new_model = \"...\" # Redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T18:54:15.332388Z",
     "iopub.status.busy": "2024-07-14T18:54:15.331994Z",
     "iopub.status.idle": "2024-07-14T18:54:15.339518Z",
     "shell.execute_reply": "2024-07-14T18:54:15.338395Z",
     "shell.execute_reply.started": "2024-07-14T18:54:15.332356Z"
    }
   },
   "outputs": [],
   "source": [
    "torch_dtype = torch.float16\n",
    "attn_implementation = \"eager\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T18:54:16.919853Z",
     "iopub.status.busy": "2024-07-14T18:54:16.919484Z",
     "iopub.status.idle": "2024-07-14T18:56:51.449058Z",
     "shell.execute_reply": "2024-07-14T18:56:51.447958Z",
     "shell.execute_reply.started": "2024-07-14T18:54:16.919825Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d31d827bd9046489d762d67d9782c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ae015fece74042a1a826a9b07bab7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d7c24bad2bd4394860d0125d33411c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c01eb7928074e1c945c60bd8300d01e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7db528a810402c9c750baff7e8d40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb60827cada94b7b87192129e1c1ac83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33a8b3d5a5d43f0801bea3ee0bfd96a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449d8083804d4bf989abc4691e44a9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b35150cb03f4f0a88a518b7be296674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# QLoRA config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T18:56:51.452791Z",
     "iopub.status.busy": "2024-07-14T18:56:51.452477Z",
     "iopub.status.idle": "2024-07-14T18:56:52.583036Z",
     "shell.execute_reply": "2024-07-14T18:56:52.581952Z",
     "shell.execute_reply.started": "2024-07-14T18:56:51.452766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f43a78412748018b29ffd8c3040535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331c32573c7c4e399329b3c46f15de77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a18333bd8254d4596e3ac1973aeb86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "model, tokenizer = setup_chat_format(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T18:56:52.584723Z",
     "iopub.status.busy": "2024-07-14T18:56:52.584373Z",
     "iopub.status.idle": "2024-07-14T18:56:53.506594Z",
     "shell.execute_reply": "2024-07-14T18:56:53.505074Z",
     "shell.execute_reply.started": "2024-07-14T18:56:52.584690Z"
    }
   },
   "outputs": [],
   "source": [
    "# LoRA config\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T15:17:15.852898Z",
     "iopub.status.busy": "2024-07-14T15:17:15.852521Z",
     "iopub.status.idle": "2024-07-14T15:17:16.000214Z",
     "shell.execute_reply": "2024-07-14T15:17:15.995583Z",
     "shell.execute_reply.started": "2024-07-14T15:17:15.852869Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset_name, split=\"all\")[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T18:56:53.510255Z",
     "iopub.status.busy": "2024-07-14T18:56:53.509280Z",
     "iopub.status.idle": "2024-07-14T18:56:53.519353Z",
     "shell.execute_reply": "2024-07-14T18:56:53.518059Z",
     "shell.execute_reply.started": "2024-07-14T18:56:53.510219Z"
    }
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T18:56:53.521873Z",
     "iopub.status.busy": "2024-07-14T18:56:53.520963Z",
     "iopub.status.idle": "2024-07-14T18:56:53.604127Z",
     "shell.execute_reply": "2024-07-14T18:56:53.602907Z",
     "shell.execute_reply.started": "2024-07-14T18:56:53.521838Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the list of dictionaries from the JSON file\n",
    "with open('/kaggle/input/pjpktxt/pjtxt.json', 'r', encoding='utf-8') as json_file:\n",
    "    pj = json.load(json_file)\n",
    "    \n",
    "with open('/kaggle/input/pjpktxt/pktxt.json', 'r', encoding='utf-8') as json_file:\n",
    "    pk = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T18:56:53.617526Z",
     "iopub.status.busy": "2024-07-14T18:56:53.616747Z",
     "iopub.status.idle": "2024-07-14T18:56:54.532587Z",
     "shell.execute_reply": "2024-07-14T18:56:54.531571Z",
     "shell.execute_reply.started": "2024-07-14T18:56:53.617480Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1001\n",
      "2002\n",
      "3003\n",
      "4004\n",
      "5005\n",
      "6006\n",
      "7007\n",
      "8008\n",
      "9009\n",
      "10010\n",
      "11011\n",
      "12012\n",
      "13013\n",
      "14014\n",
      "15015\n",
      "16016\n",
      "17017\n",
      "18018\n",
      "19019\n",
      "20020\n",
      "21021\n",
      "22022\n",
      "23023\n",
      "24024\n",
      "25025\n",
      "26026\n"
     ]
    }
   ],
   "source": [
    "dataset_final=[]\n",
    "for i in range(len(pj)):\n",
    "    raww=[{\"role\": \"user\", \"content\": pj[i]},\n",
    "           {\"role\": \"assistant\", \"content\": pk[i]}]\n",
    "    dataset_final.append(tokenizer.apply_chat_template(raww, tokenize=False))\n",
    "    if(i%1001==0):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T18:56:54.544354Z",
     "iopub.status.busy": "2024-07-14T18:56:54.543940Z",
     "iopub.status.idle": "2024-07-14T18:56:54.553374Z",
     "shell.execute_reply": "2024-07-14T18:56:54.552276Z",
     "shell.execute_reply.started": "2024-07-14T18:56:54.544319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26410"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_final) # 100000 Messages combined so multiple responses considered one as long as other doesn't reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T15:46:51.645515Z",
     "iopub.status.busy": "2024-07-14T15:46:51.644633Z",
     "iopub.status.idle": "2024-07-14T15:46:51.672981Z",
     "shell.execute_reply": "2024-07-14T15:46:51.672281Z",
     "shell.execute_reply.started": "2024-07-14T15:46:51.645480Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the list into training and testing sets\n",
    "train, test = train_test_split(dataset_final, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T15:47:08.163312Z",
     "iopub.status.busy": "2024-07-14T15:47:08.162938Z",
     "iopub.status.idle": "2024-07-14T15:47:08.171137Z",
     "shell.execute_reply": "2024-07-14T15:47:08.169508Z",
     "shell.execute_reply.started": "2024-07-14T15:47:08.163283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23769"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T18:56:54.557507Z",
     "iopub.status.busy": "2024-07-14T18:56:54.557207Z",
     "iopub.status.idle": "2024-07-14T18:56:54.583334Z",
     "shell.execute_reply": "2024-07-14T18:56:54.582227Z",
     "shell.execute_reply.started": "2024-07-14T18:56:54.557478Z"
    }
   },
   "outputs": [],
   "source": [
    "dff=[]\n",
    "for i in range(len(dataset_final)):\n",
    "    dff.append({'text':dataset_final[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T18:56:54.585470Z",
     "iopub.status.busy": "2024-07-14T18:56:54.584702Z",
     "iopub.status.idle": "2024-07-14T18:56:54.663414Z",
     "shell.execute_reply": "2024-07-14T18:56:54.662304Z",
     "shell.execute_reply.started": "2024-07-14T18:56:54.585440Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset_f = Dataset.from_list(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T18:56:54.665304Z",
     "iopub.status.busy": "2024-07-14T18:56:54.664849Z",
     "iopub.status.idle": "2024-07-14T18:56:54.673838Z",
     "shell.execute_reply": "2024-07-14T18:56:54.672643Z",
     "shell.execute_reply.started": "2024-07-14T18:56:54.665267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 26410\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T18:56:54.675687Z",
     "iopub.status.busy": "2024-07-14T18:56:54.675315Z",
     "iopub.status.idle": "2024-07-14T18:56:54.721749Z",
     "shell.execute_reply": "2024-07-14T18:56:54.721032Z",
     "shell.execute_reply.started": "2024-07-14T18:56:54.675652Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_f = dataset_f.train_test_split(test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T18:58:11.483847Z",
     "iopub.status.busy": "2024-07-14T18:58:11.482912Z",
     "iopub.status.idle": "2024-07-14T18:58:11.527841Z",
     "shell.execute_reply": "2024-07-14T18:58:11.526726Z",
     "shell.execute_reply.started": "2024-07-14T18:58:11.483808Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=new_model,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=1,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=0.05,\n",
    "    logging_steps=1,\n",
    "    warmup_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    report_to=\"wandb\",\n",
    "    save_steps=1000,  # Save less frequently\n",
    "    save_total_limit=3  # Keep only the 3 most recent checkpoints\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T18:58:14.925455Z",
     "iopub.status.busy": "2024-07-14T18:58:14.925083Z",
     "iopub.status.idle": "2024-07-14T18:58:17.148572Z",
     "shell.execute_reply": "2024-07-14T18:58:17.147326Z",
     "shell.execute_reply.started": "2024-07-14T18:58:14.925426Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2519f4166a10410bb15e5c60c5fc9158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/26145 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e0b5d92c40493aa6607948fdd79e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/265 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset_f[\"train\"],\n",
    "    eval_dataset=dataset_f[\"test\"],\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=512,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing= False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T18:58:43.600777Z",
     "iopub.status.busy": "2024-07-14T18:58:43.600417Z",
     "iopub.status.idle": "2024-07-14T23:20:55.521074Z",
     "shell.execute_reply": "2024-07-14T23:20:55.520218Z",
     "shell.execute_reply.started": "2024-07-14T18:58:43.600750Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13072' max='13072' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13072/13072 4:22:05, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>654</td>\n",
       "      <td>11.554300</td>\n",
       "      <td>11.037816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>3.612800</td>\n",
       "      <td>2.923364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1962</td>\n",
       "      <td>3.345200</td>\n",
       "      <td>2.849795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2616</td>\n",
       "      <td>4.010600</td>\n",
       "      <td>2.832273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3270</td>\n",
       "      <td>3.709800</td>\n",
       "      <td>2.790813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3924</td>\n",
       "      <td>2.846700</td>\n",
       "      <td>2.750839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4578</td>\n",
       "      <td>3.123600</td>\n",
       "      <td>2.715968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5232</td>\n",
       "      <td>2.872000</td>\n",
       "      <td>2.696605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5886</td>\n",
       "      <td>2.832400</td>\n",
       "      <td>2.662241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6540</td>\n",
       "      <td>1.602100</td>\n",
       "      <td>2.655752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7194</td>\n",
       "      <td>2.130200</td>\n",
       "      <td>2.628113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7848</td>\n",
       "      <td>1.126300</td>\n",
       "      <td>2.608767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8502</td>\n",
       "      <td>3.390500</td>\n",
       "      <td>2.601879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9156</td>\n",
       "      <td>3.111500</td>\n",
       "      <td>2.567074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9810</td>\n",
       "      <td>3.525000</td>\n",
       "      <td>2.550472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10464</td>\n",
       "      <td>2.846200</td>\n",
       "      <td>2.532086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11118</td>\n",
       "      <td>2.568800</td>\n",
       "      <td>2.511019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11772</td>\n",
       "      <td>2.772900</td>\n",
       "      <td>2.494836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12426</td>\n",
       "      <td>2.842500</td>\n",
       "      <td>2.479648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13072, training_loss=2.7019014160993486, metrics={'train_runtime': 15729.1112, 'train_samples_per_second': 1.662, 'train_steps_per_second': 0.831, 'total_flos': 3.894722285278003e+16, 'train_loss': 2.7019014160993486, 'epoch': 0.9999617517689807})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T23:21:04.211694Z",
     "iopub.status.busy": "2024-07-14T23:21:04.210878Z",
     "iopub.status.idle": "2024-07-14T23:21:10.884034Z",
     "shell.execute_reply": "2024-07-14T23:21:10.883173Z",
     "shell.execute_reply.started": "2024-07-14T23:21:04.211664Z"
    }
   },
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "model.config.use_cache = True\n",
    "\n",
    "#Output redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T23:22:31.772512Z",
     "iopub.status.busy": "2024-07-14T23:22:31.771812Z",
     "iopub.status.idle": "2024-07-14T23:22:37.522089Z",
     "shell.execute_reply": "2024-07-14T23:22:37.521290Z",
     "shell.execute_reply.started": "2024-07-14T23:22:31.772481Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.model.save_pretrained(new_model)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5384756,
     "sourceId": 8948162,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5387668,
     "sourceId": 8952404,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 81009,
     "modelInstanceId": 58613,
     "sourceId": 70226,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
